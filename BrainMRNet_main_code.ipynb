{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33738,
     "status": "ok",
     "timestamp": 1636614965187,
     "user": {
      "displayName": "Shyam 5 project",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01454073121946861679"
     },
     "user_tz": -330
    },
    "id": "oY4ffYPhGdIE",
    "outputId": "376cdb30-5a36-4eb2-9880-30d9e85be29f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from albumentations import *\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support, accuracy_score\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.models import load_model, Model\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement albumenations\n",
      "ERROR: No matching distribution found for albumenations\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sl3WnfTa4jYm"
   },
   "outputs": [],
   "source": [
    "SHAPE = (224, 224, 3)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "N_SPLITS = 2\n",
    "SEED = 1881\n",
    "TRAIN_TEST_RATIO = 0.3\n",
    "BASE_DIR     = ('/content/drive/MyDrive/brainmri_net/brain_tumor_dataset/')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3N_BczpUd7qG"
   },
   "outputs": [],
   "source": [
    "categories = ['yes', 'no']\n",
    "yes_path = os.path.join(BASE_DIR,categories[0])\n",
    "no_path = os.path.join(BASE_DIR,categories[1])\n",
    "yes_images = os.listdir(yes_path)\n",
    "no_images = os.listdir(no_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEWuPSgEgATs"
   },
   "outputs": [],
   "source": [
    "yes_img_path = []\n",
    "for i in yes_images:\n",
    "  path = os.path.join(yes_path,i)\n",
    "  yes_img_path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJ729Uaugjmm"
   },
   "outputs": [],
   "source": [
    "no_img_path = []\n",
    "for i in no_images:\n",
    "  path = os.path.join(no_path,i)\n",
    "  no_img_path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgMfHhGHhS2R"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HtXdFCChhWsJ"
   },
   "outputs": [],
   "source": [
    "BASE_DIR.extend(yes_img_path)\n",
    "BASE_DIR.extend(no_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGT_8VyTZt2T"
   },
   "outputs": [],
   "source": [
    "class DATASET:\n",
    "\n",
    "    \"\"\"\n",
    "    input_shape           --> TUPLE.wanted image size\n",
    "    batch_size            --> INT.yielding data size for every iteration\n",
    "    orders                --> LIST.which images will be used. max=len(all_images). it can be used for K-fold(CV).\n",
    "    base_dir              --> STR.the DIR which is include images.\n",
    "    seed                  --> INT. This allow to dataset generator to more reproduciable and it ensures that x and y are shuffled with compatible.\n",
    "    augment               --> BOOL. Augment data or not.\n",
    "    train_test_ratio      --> How much of data will be used as test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape, batch_size, orders, base_dir, seed, train_test_ratio, augment=True):\n",
    "        self.SHAPE                 = input_shape\n",
    "        self.BATCH_SIZE            = batch_size\n",
    "        self.arr                   = orders\n",
    "        self.SEED                  = seed\n",
    "        self.TT_RATIO              = train_test_ratio\n",
    "        self.AUG                   = augment\n",
    "        \n",
    "        self.BASE_DIR              = base_dir\n",
    "        \n",
    "        \n",
    "    def get_paths_n_labels(self):\n",
    "\n",
    "        x     = []\n",
    "        label = []\n",
    "        \n",
    "        img_paths = self.BASE_DIR\n",
    "        \n",
    "        for img_path in img_paths:\n",
    "           \n",
    "            if (\"yes\" in img_path):\n",
    "                x.append(img_path)\n",
    "                label.append([1,0])\n",
    "            else:\n",
    "                x.append(img_path)\n",
    "                label.append([0,1])\n",
    "                \n",
    "        return x, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.get_paths_n_labels()[0])\n",
    "    \n",
    "    def get_img(self, img_path):\n",
    "        img = Image.open(img_path)\n",
    "        return np.array(img)\n",
    "    \n",
    "    def augmenting(self, img):\n",
    "        if self.AUG:\n",
    "            augment = Compose([VerticalFlip(p=0.5),\n",
    "                               HorizontalFlip(p=0.5),\n",
    "                               RandomBrightnessContrast(p=0.3),\n",
    "                               ShiftScaleRotate(p=0.5, shift_limit=0.2, scale_limit=0.2, rotate_limit=20)])   \n",
    "        else:\n",
    "            augment = Compose([])  \n",
    "\n",
    "        img = augment(image=img)['image']\n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def resize_and_normalize(self, img):\n",
    "        img = resize(img, self.SHAPE)\n",
    "        return img\n",
    "    \n",
    "    def get_shuffled_data(self):\n",
    "        img_paths, labels = self.get_paths_n_labels()\n",
    "\n",
    "        np.random.seed(self.SEED) \n",
    "        np.random.shuffle(img_paths)\n",
    "        \n",
    "        np.random.seed(self.SEED) \n",
    "        np.random.shuffle(labels)\n",
    "        \n",
    "        return img_paths, labels\n",
    "        \n",
    "    def split_train_test(self, get):  # get=={\"train\",\"test\"}\n",
    "        img_paths, labels = self.get_shuffled_data()\n",
    "        x_train, x_test, y_train, y_test = train_test_split(img_paths, labels, test_size=self.TT_RATIO, random_state=self.SEED)\n",
    "        \n",
    "        if get=='train':\n",
    "            return x_train, y_train\n",
    "        \n",
    "        elif get=='test':\n",
    "            return x_test, y_test\n",
    "    \n",
    "    def data_generator(self):\n",
    "        img_paths, labels = self.split_train_test(get=\"train\")\n",
    "        \n",
    "        while True:\n",
    "            x = np.empty((self.BATCH_SIZE,)+self.SHAPE, dtype=np.float32)\n",
    "            y = np.empty((self.BATCH_SIZE, 2), dtype=np.float32)\n",
    "\n",
    "            batch = np.random.choice(self.arr, self.BATCH_SIZE)\n",
    "\n",
    "            for ix, id_ in enumerate(batch):\n",
    "                # x\n",
    "                img_path = img_paths[id_]\n",
    "                img = self.get_img(img_path)\n",
    "                img = self.augmenting(img)\n",
    "                img = self.resize_and_normalize(img)\n",
    "                  \n",
    "                # y \n",
    "                label = labels[id_]\n",
    "             \n",
    "                # Store the values    \n",
    "                x[ix] = img\n",
    "                y[ix] = label\n",
    "\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1447,
     "status": "ok",
     "timestamp": 1636617683390,
     "user": {
      "displayName": "Shyam 5 project",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01454073121946861679"
     },
     "user_tz": -330
    },
    "id": "bJ-aVohsqt1F",
    "outputId": "87da2c93-a860-435c-91ae-1010409388c1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]]\n",
      "(1, 224, 224, 3)\n",
      "----------\n",
      "[[0. 1.]]\n",
      "(1, 2)\n",
      "----------\n",
      "(224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = DATASET(SHAPE, 1, range(4), BASE_DIR, SEED, TRAIN_TEST_RATIO, augment=True)\n",
    "\n",
    "for ix, data in enumerate(dataset.data_generator()):\n",
    "    img, y = data\n",
    "    print(img)\n",
    "    print(img.shape)\n",
    "    print(\"-\"*10)\n",
    "    print(y)\n",
    "    print(y.shape)\n",
    "    print(\"-\"*10)\n",
    "    print(img[0,:,:,:].shape)\n",
    "    plt.imshow(img[0,:,:,:])\n",
    "    plt.show()\n",
    "    \n",
    "    if ix==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZygcwwp0Sry"
   },
   "outputs": [],
   "source": [
    "# credits: https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Recall metric.\n",
    "    \n",
    "    Only computes a batch-wise average of recall.\n",
    "    \n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    \n",
    "    Only computes a batch-wise average of precision.\n",
    "    \n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    precisionx = precision(y_true, y_pred)\n",
    "    recallx = recall(y_true, y_pred)\n",
    "    return 2*((precisionx*recallx)/(precisionx+recallx+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBbVuHAfgHnh"
   },
   "outputs": [],
   "source": [
    "class SGDRScheduler(Callback):\n",
    "    '''Cosine annealing learning rate scheduler with periodic restarts.\n",
    "    # Usage\n",
    "        ```python\n",
    "            schedule = SGDRScheduler(min_lr=1e-5,\n",
    "                                     max_lr=1e-2,\n",
    "                                     steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                                     lr_decay=0.9,\n",
    "                                     cycle_length=5,\n",
    "                                     mult_factor=1.5)\n",
    "            model.fit(X_train, Y_train, epochs=100, callbacks=[schedule])\n",
    "        ```\n",
    "    # Arguments\n",
    "        min_lr: The lower bound of the learning rate range for the experiment.\n",
    "        max_lr: The upper bound of the learning rate range for the experiment.\n",
    "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`. \n",
    "        lr_decay: Reduce the max_lr after the completion of each cycle.\n",
    "                  Ex. To reduce the max_lr by 20% after each cycle, set this value to 0.8.\n",
    "        cycle_length: Initial number of epochs in a cycle.\n",
    "        mult_factor: Scale epochs_to_restart after each full cycle completion.\n",
    "    # References\n",
    "        Blog post: jeremyjordan.me/nn-learning-rate\n",
    "        Original paper: http://arxiv.org/abs/1608.03983\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 min_lr,\n",
    "                 max_lr,\n",
    "                 steps_per_epoch,\n",
    "                 lr_decay=0.9, #1 oldu\n",
    "                 cycle_length=5,\n",
    "                 mult_factor=1.5):  #2 oldu\n",
    "\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.lr_decay = lr_decay\n",
    "\n",
    "        self.batch_since_restart = 0\n",
    "        self.next_restart = cycle_length\n",
    "\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "        self.cycle_length = cycle_length\n",
    "        self.mult_factor = mult_factor\n",
    "\n",
    "        self.history = {}\n",
    "\n",
    "    def clr(self):\n",
    "        '''Calculate the learning rate.'''\n",
    "        fraction_to_restart = self.batch_since_restart / (self.steps_per_epoch * self.cycle_length)\n",
    "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(fraction_to_restart * np.pi))\n",
    "        return lr\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
    "        logs = logs or {}\n",
    "        K.set_value(self.model.optimizer.lr, self.max_lr)\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        '''Record previous batch statistics and update the learning rate.'''\n",
    "        logs = logs or {}\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "\n",
    "        self.batch_since_restart += 1\n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        '''Check for end of current cycle, apply restarts when necessary.'''\n",
    "        if epoch + 1 == self.next_restart:\n",
    "            self.batch_since_restart = 0\n",
    "            self.cycle_length = np.ceil(self.cycle_length * self.mult_factor)\n",
    "            self.next_restart += self.cycle_length\n",
    "            self.max_lr *= self.lr_decay\n",
    "            self.best_weights = self.model.get_weights()\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        '''Set weights to the values from the end of the most recent cycle for best performance.'''\n",
    "        self.model.set_weights(self.best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvvEuAAKfkV5"
   },
   "outputs": [],
   "source": [
    "# copied from https://github.com/kobiso/CBAM-keras/blob/master/models/attention_module.py\n",
    "def cbam_block(cbam_feature, ratio=8):\n",
    "    \"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "    As described in https://arxiv.org/abs/1807.06521.\n",
    "    \"\"\"\n",
    "    \n",
    "    cbam_feature = channel_attention(cbam_feature, ratio)\n",
    "    cbam_feature = spatial_attention(cbam_feature)\n",
    "    return cbam_feature\n",
    "\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    channel = input_feature.shape[channel_axis]\n",
    "    \n",
    "    shared_layer_one = Dense(channel//ratio,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    shared_layer_two = Dense(channel,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling2D()(input_feature)    \n",
    "    avg_pool = Reshape((1,1,channel))(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel//ratio)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel)\n",
    "    \n",
    "    max_pool = GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = Reshape((1,1,channel))(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel//ratio)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel)\n",
    "    \n",
    "    cbam_feature = Add()([avg_pool,max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "    \n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n",
    "def spatial_attention(input_feature):\n",
    "    kernel_size = 7\n",
    "    \n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        channel = input_feature.shape[1]\n",
    "        cbam_feature = Permute((2,3,1))(input_feature)\n",
    "    else:\n",
    "        channel = input_feature.shape[-1]\n",
    "        cbam_feature = input_feature\n",
    "    \n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert avg_pool.shape[-1] == 1\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert max_pool.shape[-1] == 1\n",
    "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    assert concat.shape[-1] == 2\n",
    "    cbam_feature = Conv2D(filters = 1,\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=1,\n",
    "                    padding='same',\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    use_bias=False)(concat)\t\n",
    "    assert cbam_feature.shape[-1] == 1\n",
    "    \n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "        \n",
    "    return multiply([input_feature, cbam_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4Ndx2vm6NZ3"
   },
   "outputs": [],
   "source": [
    "# copied from https://gist.github.com/mjdietzx/5319e42637ed7ef095d430cb5c5e8c64\n",
    "def residual_block(y, nb_channels, _strides=(1, 1), _project_shortcut=False):\n",
    "    shortcut = y\n",
    "\n",
    "    # down-sampling is performed with a stride of 2\n",
    "    y = Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LeakyReLU()(y)\n",
    "\n",
    "    y = Conv2D(nb_channels, kernel_size=(3, 3), strides=(1, 1), padding='same')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    # identity shortcuts used directly when the input and output are of the same dimensions\n",
    "    if _project_shortcut or _strides != (1, 1):\n",
    "        # when the dimensions increase projection shortcut is used to match dimensions (done by 1×1 convolutions)\n",
    "        # when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2\n",
    "        shortcut = Conv2D(nb_channels, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    y = add([shortcut, y])\n",
    "    y = LeakyReLU()(y)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVUWz9lzfm6Y"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    dropRate = 0.3\n",
    "    \n",
    "    init = Input(SHAPE)\n",
    "    x = Conv2D(32, (3, 3), activation=None, padding='same')(init) \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(32, (3, 3), activation=None, padding='same')(x) \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x1 = MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation=None, padding='same')(x1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = cbam_block(x)\n",
    "    x = residual_block(x, 64)\n",
    "    x2 = MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), activation=None, padding='same')(x2)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = cbam_block(x)\n",
    "    x = residual_block(x, 128)\n",
    "    x3 = MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    ginp1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(x1)\n",
    "    ginp2 = UpSampling2D(size=(4, 4), interpolation='bilinear')(x2)\n",
    "    ginp3 = UpSampling2D(size=(8, 8), interpolation='bilinear')(x3)\n",
    "    \n",
    "    hypercolumn = Concatenate()([ginp1, ginp2, ginp3]) \n",
    "    gap = GlobalAveragePooling2D()(hypercolumn)\n",
    "\n",
    "    x = Dense(256, activation=None)(gap)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    \n",
    "    x = Dense(256, activation=None)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    y = Dense(2, activation='softmax')(x)\n",
    "   \n",
    "    model = Model(init, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1636617691564,
     "user": {
      "displayName": "Shyam 5 project",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01454073121946861679"
     },
     "user_tz": -330
    },
    "id": "w2V3AUW7fm-n",
    "outputId": "b60f6a48-2055-4cb7-a57d-25883ff4d975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 224, 224, 32  896         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 224, 224, 32  128        ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 224, 224, 32  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 224, 224, 32  9248        ['activation_8[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 224, 224, 32  128        ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 224, 224, 32  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 112, 112, 32  0          ['activation_9[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 112, 112, 64  18496       ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 112, 112, 64  256        ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 112, 112, 64  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 64)          0           ['activation_10[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling2d_2 (Global  (None, 64)          0           ['activation_10[0][0]']          \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 1, 1, 64)     0           ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 1, 1, 64)     0           ['global_max_pooling2d_2[0][0]'] \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1, 1, 8)      520         ['reshape_4[0][0]',              \n",
      "                                                                  'reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1, 1, 64)     576         ['dense_7[0][0]',                \n",
      "                                                                  'dense_7[1][0]']                \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 1, 1, 64)     0           ['dense_8[0][0]',                \n",
      "                                                                  'dense_8[1][0]']                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 1, 1, 64)     0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 112, 112, 64  0           ['activation_10[0][0]',          \n",
      "                                )                                 'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 112, 112, 1)  0           ['multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              (None, 112, 112, 1)  0           ['multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 112, 112, 2)  0           ['lambda_4[0][0]',               \n",
      "                                                                  'lambda_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 112, 112, 1)  98          ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 112, 112, 64  0           ['multiply_4[0][0]',             \n",
      "                                )                                 'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 112, 112, 64  36928       ['multiply_5[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 112, 112, 64  256        ['conv2d_14[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 112, 112, 64  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 112, 112, 64  36928       ['leaky_re_lu_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 112, 112, 64  256        ['conv2d_15[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 112, 112, 64  0           ['multiply_5[0][0]',             \n",
      "                                )                                 'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 112, 112, 64  0           ['add_5[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 56, 56, 64)  0           ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 56, 56, 128)  73856       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 56, 56, 128)  512        ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 56, 56, 128)  0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4 (Gl  (None, 128)         0           ['activation_12[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling2d_3 (Global  (None, 128)         0           ['activation_12[0][0]']          \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 1, 1, 128)    0           ['global_max_pooling2d_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1, 1, 16)     2064        ['reshape_6[0][0]',              \n",
      "                                                                  'reshape_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1, 1, 128)    2176        ['dense_9[0][0]',                \n",
      "                                                                  'dense_9[1][0]']                \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 1, 1, 128)    0           ['dense_10[0][0]',               \n",
      "                                                                  'dense_10[1][0]']               \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 1, 1, 128)    0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 56, 56, 128)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, 56, 56, 1)    0           ['multiply_6[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              (None, 56, 56, 1)    0           ['multiply_6[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 56, 56, 2)    0           ['lambda_6[0][0]',               \n",
      "                                                                  'lambda_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 56, 56, 1)    98          ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 56, 56, 128)  0           ['multiply_6[0][0]',             \n",
      "                                                                  'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 56, 56, 128)  147584      ['multiply_7[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 56, 56, 128)  512        ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 56, 56, 128)  0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 56, 56, 128)  147584      ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 56, 56, 128)  512        ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 56, 56, 128)  0           ['multiply_7[0][0]',             \n",
      "                                                                  'batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 56, 56, 128)  0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 28, 28, 128)  0          ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 224, 224, 32  0          ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64  0          ['max_pooling2d_4[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 12  0          ['max_pooling2d_5[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 224, 224, 22  0           ['up_sampling2d_3[0][0]',        \n",
      "                                4)                                'up_sampling2d_4[0][0]',        \n",
      "                                                                  'up_sampling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 224)         0           ['concatenate_5[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 256)          57600       ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 256)         1024        ['dense_11[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 256)          0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 256)          0           ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 256)          65792       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 256)         1024        ['dense_12[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 256)          0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 2)            514         ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 605,566\n",
      "Trainable params: 603,262\n",
      "Non-trainable params: 2,304\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1465370,
     "status": "ok",
     "timestamp": 1636619156932,
     "user": {
      "displayName": "Shyam 5 project",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01454073121946861679"
     },
     "user_tz": -330
    },
    "id": "MSHMA1gtMQ6e",
    "outputId": "59b22aba-91f7-47a6-eb83-5f3f41dcc6d7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69524, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 12s - loss: 0.7576 - precision: 0.6375 - recall: 0.6375 - f1: 0.6375 - acc: 0.6375 - val_loss: 0.6952 - val_precision: 0.3000 - val_recall: 0.3000 - val_f1: 0.3000 - val_acc: 0.3000 - 12s/epoch - 2s/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.69524\n",
      "5/5 - 7s - loss: 0.7052 - precision: 0.6500 - recall: 0.6500 - f1: 0.6500 - acc: 0.6500 - val_loss: 0.6993 - val_precision: 0.3875 - val_recall: 0.3875 - val_f1: 0.3875 - val_acc: 0.3875 - 7s/epoch - 1s/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.69524\n",
      "5/5 - 6s - loss: 0.6525 - precision: 0.7125 - recall: 0.7125 - f1: 0.7125 - acc: 0.7125 - val_loss: 0.6980 - val_precision: 0.3625 - val_recall: 0.3625 - val_f1: 0.3625 - val_acc: 0.3625 - 6s/epoch - 1s/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.69524 to 0.68998, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 6s - loss: 0.5143 - precision: 0.8000 - recall: 0.8000 - f1: 0.8000 - acc: 0.8000 - val_loss: 0.6900 - val_precision: 0.5500 - val_recall: 0.5500 - val_f1: 0.5500 - val_acc: 0.5500 - 6s/epoch - 1s/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.68998 to 0.68079, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 9s - loss: 0.5619 - precision: 0.7625 - recall: 0.7625 - f1: 0.7625 - acc: 0.7625 - val_loss: 0.6808 - val_precision: 0.6500 - val_recall: 0.6500 - val_f1: 0.6500 - val_acc: 0.6500 - 9s/epoch - 2s/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68079 to 0.67370, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 7s - loss: 0.4438 - precision: 0.8250 - recall: 0.8250 - f1: 0.8250 - acc: 0.8250 - val_loss: 0.6737 - val_precision: 0.7000 - val_recall: 0.7000 - val_f1: 0.7000 - val_acc: 0.7000 - 7s/epoch - 1s/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.67370\n",
      "5/5 - 8s - loss: 0.4249 - precision: 0.7750 - recall: 0.7750 - f1: 0.7750 - acc: 0.7750 - val_loss: 0.6755 - val_precision: 0.6375 - val_recall: 0.6375 - val_f1: 0.6375 - val_acc: 0.6375 - 8s/epoch - 2s/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.67370 to 0.65331, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 7s - loss: 0.4739 - precision: 0.7500 - recall: 0.7500 - f1: 0.7500 - acc: 0.7500 - val_loss: 0.6533 - val_precision: 0.7375 - val_recall: 0.7375 - val_f1: 0.7375 - val_acc: 0.7375 - 7s/epoch - 1s/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.65331\n",
      "5/5 - 6s - loss: 0.5013 - precision: 0.7750 - recall: 0.7750 - f1: 0.7750 - acc: 0.7750 - val_loss: 0.6636 - val_precision: 0.6500 - val_recall: 0.6500 - val_f1: 0.6500 - val_acc: 0.6500 - 6s/epoch - 1s/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.65331\n",
      "5/5 - 6s - loss: 0.5587 - precision: 0.6875 - recall: 0.6875 - f1: 0.6875 - acc: 0.6875 - val_loss: 0.6850 - val_precision: 0.5500 - val_recall: 0.5500 - val_f1: 0.5500 - val_acc: 0.5500 - 6s/epoch - 1s/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.65331 to 0.64844, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 6s - loss: 0.4859 - precision: 0.8125 - recall: 0.8125 - f1: 0.8125 - acc: 0.8125 - val_loss: 0.6484 - val_precision: 0.6875 - val_recall: 0.6875 - val_f1: 0.6875 - val_acc: 0.6875 - 6s/epoch - 1s/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.64844\n",
      "5/5 - 6s - loss: 0.4502 - precision: 0.8125 - recall: 0.8125 - f1: 0.8125 - acc: 0.8125 - val_loss: 0.6486 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 6s/epoch - 1s/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.64844\n",
      "5/5 - 6s - loss: 0.5726 - precision: 0.7125 - recall: 0.7125 - f1: 0.7125 - acc: 0.7125 - val_loss: 0.6555 - val_precision: 0.6625 - val_recall: 0.6625 - val_f1: 0.6625 - val_acc: 0.6625 - 6s/epoch - 1s/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.64844\n",
      "5/5 - 6s - loss: 0.4668 - precision: 0.7875 - recall: 0.7875 - f1: 0.7875 - acc: 0.7875 - val_loss: 0.6492 - val_precision: 0.6625 - val_recall: 0.6625 - val_f1: 0.6625 - val_acc: 0.6625 - 6s/epoch - 1s/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.64844 to 0.63646, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 8s - loss: 0.4134 - precision: 0.8625 - recall: 0.8625 - f1: 0.8625 - acc: 0.8625 - val_loss: 0.6365 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 8s/epoch - 2s/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.63646\n",
      "5/5 - 9s - loss: 0.4751 - precision: 0.8000 - recall: 0.8000 - f1: 0.8000 - acc: 0.8000 - val_loss: 0.6459 - val_precision: 0.6500 - val_recall: 0.6500 - val_f1: 0.6500 - val_acc: 0.6500 - 9s/epoch - 2s/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.63646 to 0.63167, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 9s - loss: 0.4214 - precision: 0.7500 - recall: 0.7500 - f1: 0.7500 - acc: 0.7500 - val_loss: 0.6317 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 9s/epoch - 2s/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.63167\n",
      "5/5 - 9s - loss: 0.2836 - precision: 0.8750 - recall: 0.8750 - f1: 0.8750 - acc: 0.8750 - val_loss: 0.6400 - val_precision: 0.6500 - val_recall: 0.6500 - val_f1: 0.6500 - val_acc: 0.6500 - 9s/epoch - 2s/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.63167 to 0.60343, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 7s - loss: 0.3924 - precision: 0.8625 - recall: 0.8625 - f1: 0.8625 - acc: 0.8625 - val_loss: 0.6034 - val_precision: 0.7375 - val_recall: 0.7375 - val_f1: 0.7375 - val_acc: 0.7375 - 7s/epoch - 1s/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.60343\n",
      "5/5 - 6s - loss: 0.4487 - precision: 0.8250 - recall: 0.8250 - f1: 0.8250 - acc: 0.8250 - val_loss: 0.6706 - val_precision: 0.5875 - val_recall: 0.5875 - val_f1: 0.5875 - val_acc: 0.5875 - 6s/epoch - 1s/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.60343 to 0.60106, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 6s - loss: 0.6231 - precision: 0.7250 - recall: 0.7250 - f1: 0.7250 - acc: 0.7250 - val_loss: 0.6011 - val_precision: 0.7250 - val_recall: 0.7250 - val_f1: 0.7250 - val_acc: 0.7250 - 6s/epoch - 1s/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.60106\n",
      "5/5 - 8s - loss: 0.4078 - precision: 0.8375 - recall: 0.8375 - f1: 0.8375 - acc: 0.8375 - val_loss: 0.6658 - val_precision: 0.5875 - val_recall: 0.5875 - val_f1: 0.5875 - val_acc: 0.5875 - 8s/epoch - 2s/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.60106 to 0.56684, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 8s - loss: 0.4085 - precision: 0.8125 - recall: 0.8125 - f1: 0.8125 - acc: 0.8125 - val_loss: 0.5668 - val_precision: 0.7875 - val_recall: 0.7875 - val_f1: 0.7875 - val_acc: 0.7875 - 8s/epoch - 2s/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.56684\n",
      "5/5 - 7s - loss: 0.4975 - precision: 0.7500 - recall: 0.7500 - f1: 0.7500 - acc: 0.7500 - val_loss: 0.6798 - val_precision: 0.5500 - val_recall: 0.5500 - val_f1: 0.5500 - val_acc: 0.5500 - 7s/epoch - 1s/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.56684\n",
      "5/5 - 7s - loss: 0.4016 - precision: 0.8250 - recall: 0.8250 - f1: 0.8250 - acc: 0.8250 - val_loss: 0.6085 - val_precision: 0.7125 - val_recall: 0.7125 - val_f1: 0.7125 - val_acc: 0.7125 - 7s/epoch - 1s/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.56684\n",
      "5/5 - 9s - loss: 0.4262 - precision: 0.8250 - recall: 0.8250 - f1: 0.8250 - acc: 0.8250 - val_loss: 0.5927 - val_precision: 0.7375 - val_recall: 0.7375 - val_f1: 0.7375 - val_acc: 0.7375 - 9s/epoch - 2s/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.56684\n",
      "5/5 - 8s - loss: 0.4275 - precision: 0.8375 - recall: 0.8375 - f1: 0.8375 - acc: 0.8375 - val_loss: 0.6268 - val_precision: 0.6500 - val_recall: 0.6500 - val_f1: 0.6500 - val_acc: 0.6500 - 8s/epoch - 2s/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.56684\n",
      "5/5 - 8s - loss: 0.2976 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 0.6146 - val_precision: 0.7000 - val_recall: 0.7000 - val_f1: 0.7000 - val_acc: 0.7000 - 8s/epoch - 2s/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.56684\n",
      "5/5 - 7s - loss: 0.3380 - precision: 0.8500 - recall: 0.8500 - f1: 0.8500 - acc: 0.8500 - val_loss: 0.6037 - val_precision: 0.7000 - val_recall: 0.7000 - val_f1: 0.7000 - val_acc: 0.7000 - 7s/epoch - 1s/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.56684\n",
      "5/5 - 6s - loss: 0.4589 - precision: 0.8250 - recall: 0.8250 - f1: 0.8250 - acc: 0.8250 - val_loss: 0.5979 - val_precision: 0.6875 - val_recall: 0.6875 - val_f1: 0.6875 - val_acc: 0.6875 - 6s/epoch - 1s/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.56684\n",
      "5/5 - 8s - loss: 0.3227 - precision: 0.8500 - recall: 0.8500 - f1: 0.8500 - acc: 0.8500 - val_loss: 0.6948 - val_precision: 0.5750 - val_recall: 0.5750 - val_f1: 0.5750 - val_acc: 0.5750 - 8s/epoch - 2s/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.56684\n",
      "5/5 - 9s - loss: 0.3294 - precision: 0.8375 - recall: 0.8375 - f1: 0.8375 - acc: 0.8375 - val_loss: 0.5731 - val_precision: 0.7000 - val_recall: 0.7000 - val_f1: 0.7000 - val_acc: 0.7000 - 9s/epoch - 2s/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.56684\n",
      "5/5 - 6s - loss: 0.5016 - precision: 0.8000 - recall: 0.8000 - f1: 0.8000 - acc: 0.8000 - val_loss: 0.6248 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 6s/epoch - 1s/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.56684 to 0.53312, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 7s - loss: 0.3582 - precision: 0.8500 - recall: 0.8500 - f1: 0.8500 - acc: 0.8500 - val_loss: 0.5331 - val_precision: 0.7375 - val_recall: 0.7375 - val_f1: 0.7375 - val_acc: 0.7375 - 7s/epoch - 1s/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.53312\n",
      "5/5 - 7s - loss: 0.4027 - precision: 0.8625 - recall: 0.8625 - f1: 0.8625 - acc: 0.8625 - val_loss: 0.6147 - val_precision: 0.6500 - val_recall: 0.6500 - val_f1: 0.6500 - val_acc: 0.6500 - 7s/epoch - 1s/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.53312\n",
      "5/5 - 9s - loss: 0.3983 - precision: 0.7875 - recall: 0.7875 - f1: 0.7875 - acc: 0.7875 - val_loss: 0.5980 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 9s/epoch - 2s/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.53312\n",
      "5/5 - 7s - loss: 0.4249 - precision: 0.8375 - recall: 0.8375 - f1: 0.8375 - acc: 0.8375 - val_loss: 0.6437 - val_precision: 0.6500 - val_recall: 0.6500 - val_f1: 0.6500 - val_acc: 0.6500 - 7s/epoch - 1s/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.53312\n",
      "5/5 - 6s - loss: 0.3694 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 0.5886 - val_precision: 0.8125 - val_recall: 0.8125 - val_f1: 0.8125 - val_acc: 0.8125 - 6s/epoch - 1s/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.53312\n",
      "5/5 - 9s - loss: 0.3684 - precision: 0.8625 - recall: 0.8625 - f1: 0.8625 - acc: 0.8625 - val_loss: 0.5816 - val_precision: 0.7875 - val_recall: 0.7875 - val_f1: 0.7875 - val_acc: 0.7875 - 9s/epoch - 2s/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.53312\n",
      "5/5 - 6s - loss: 0.4345 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 0.5602 - val_precision: 0.6875 - val_recall: 0.6875 - val_f1: 0.6875 - val_acc: 0.6875 - 6s/epoch - 1s/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.53312\n",
      "5/5 - 9s - loss: 0.2611 - precision: 0.9000 - recall: 0.9000 - f1: 0.9000 - acc: 0.9000 - val_loss: 0.5723 - val_precision: 0.7125 - val_recall: 0.7125 - val_f1: 0.7125 - val_acc: 0.7125 - 9s/epoch - 2s/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.53312\n",
      "5/5 - 8s - loss: 0.4176 - precision: 0.7875 - recall: 0.7875 - f1: 0.7875 - acc: 0.7875 - val_loss: 0.6372 - val_precision: 0.6375 - val_recall: 0.6375 - val_f1: 0.6375 - val_acc: 0.6375 - 8s/epoch - 2s/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.53312\n",
      "5/5 - 7s - loss: 0.3190 - precision: 0.8375 - recall: 0.8375 - f1: 0.8375 - acc: 0.8375 - val_loss: 0.5969 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 7s/epoch - 1s/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.53312\n",
      "5/5 - 9s - loss: 0.5661 - precision: 0.7875 - recall: 0.7875 - f1: 0.7875 - acc: 0.7875 - val_loss: 0.6626 - val_precision: 0.6000 - val_recall: 0.6000 - val_f1: 0.6000 - val_acc: 0.6000 - 9s/epoch - 2s/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.53312 to 0.52849, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 9s - loss: 0.4006 - precision: 0.8000 - recall: 0.8000 - f1: 0.8000 - acc: 0.8000 - val_loss: 0.5285 - val_precision: 0.7125 - val_recall: 0.7125 - val_f1: 0.7125 - val_acc: 0.7125 - 9s/epoch - 2s/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.52849\n",
      "5/5 - 7s - loss: 0.2890 - precision: 0.8625 - recall: 0.8625 - f1: 0.8625 - acc: 0.8625 - val_loss: 0.6050 - val_precision: 0.6500 - val_recall: 0.6500 - val_f1: 0.6500 - val_acc: 0.6500 - 7s/epoch - 1s/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.52849\n",
      "5/5 - 7s - loss: 0.2502 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 0.5509 - val_precision: 0.7000 - val_recall: 0.7000 - val_f1: 0.7000 - val_acc: 0.7000 - 7s/epoch - 1s/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.2354 - precision: 0.9000 - recall: 0.9000 - f1: 0.9000 - acc: 0.9000 - val_loss: 0.5429 - val_precision: 0.7375 - val_recall: 0.7375 - val_f1: 0.7375 - val_acc: 0.7375 - 6s/epoch - 1s/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.52849\n",
      "5/5 - 8s - loss: 0.2695 - precision: 0.9000 - recall: 0.9000 - f1: 0.9000 - acc: 0.9000 - val_loss: 0.6036 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 8s/epoch - 2s/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.3428 - precision: 0.8750 - recall: 0.8750 - f1: 0.8750 - acc: 0.8750 - val_loss: 0.5877 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 6s/epoch - 1s/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.52849\n",
      "5/5 - 7s - loss: 0.2287 - precision: 0.8750 - recall: 0.8750 - f1: 0.8750 - acc: 0.8750 - val_loss: 0.5900 - val_precision: 0.7000 - val_recall: 0.7000 - val_f1: 0.7000 - val_acc: 0.7000 - 7s/epoch - 1s/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.52849\n",
      "5/5 - 9s - loss: 0.4445 - precision: 0.7875 - recall: 0.7875 - f1: 0.7875 - acc: 0.7875 - val_loss: 0.5966 - val_precision: 0.8000 - val_recall: 0.8000 - val_f1: 0.8000 - val_acc: 0.8000 - 9s/epoch - 2s/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.52849\n",
      "5/5 - 8s - loss: 0.2398 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 0.6402 - val_precision: 0.6125 - val_recall: 0.6125 - val_f1: 0.6125 - val_acc: 0.6125 - 8s/epoch - 2s/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.2295 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 0.7224 - val_precision: 0.5750 - val_recall: 0.5750 - val_f1: 0.5750 - val_acc: 0.5750 - 6s/epoch - 1s/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.52849\n",
      "5/5 - 8s - loss: 0.2414 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 0.6649 - val_precision: 0.6375 - val_recall: 0.6375 - val_f1: 0.6375 - val_acc: 0.6375 - 8s/epoch - 2s/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.2728 - precision: 0.8625 - recall: 0.8625 - f1: 0.8625 - acc: 0.8625 - val_loss: 0.5972 - val_precision: 0.7125 - val_recall: 0.7125 - val_f1: 0.7125 - val_acc: 0.7125 - 6s/epoch - 1s/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.52849\n",
      "5/5 - 7s - loss: 0.2397 - precision: 0.8750 - recall: 0.8750 - f1: 0.8750 - acc: 0.8750 - val_loss: 0.5714 - val_precision: 0.6875 - val_recall: 0.6875 - val_f1: 0.6875 - val_acc: 0.6875 - 7s/epoch - 1s/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.52849\n",
      "5/5 - 7s - loss: 0.3237 - precision: 0.8375 - recall: 0.8375 - f1: 0.8375 - acc: 0.8375 - val_loss: 0.6884 - val_precision: 0.6625 - val_recall: 0.6625 - val_f1: 0.6625 - val_acc: 0.6625 - 7s/epoch - 1s/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.52849\n",
      "5/5 - 7s - loss: 0.2086 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 0.7324 - val_precision: 0.4500 - val_recall: 0.4500 - val_f1: 0.4500 - val_acc: 0.4500 - 7s/epoch - 1s/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.2006 - precision: 0.9000 - recall: 0.9000 - f1: 0.9000 - acc: 0.9000 - val_loss: 0.7924 - val_precision: 0.4500 - val_recall: 0.4500 - val_f1: 0.4500 - val_acc: 0.4500 - 6s/epoch - 1s/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.2131 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 0.8079 - val_precision: 0.4875 - val_recall: 0.4875 - val_f1: 0.4875 - val_acc: 0.4875 - 6s/epoch - 1s/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.2026 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 0.8230 - val_precision: 0.4625 - val_recall: 0.4625 - val_f1: 0.4625 - val_acc: 0.4625 - 6s/epoch - 1s/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.52849\n",
      "5/5 - 8s - loss: 0.2496 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 0.7847 - val_precision: 0.5500 - val_recall: 0.5500 - val_f1: 0.5500 - val_acc: 0.5500 - 8s/epoch - 2s/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.1874 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 1.0219 - val_precision: 0.3375 - val_recall: 0.3375 - val_f1: 0.3375 - val_acc: 0.3375 - 6s/epoch - 1s/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.52849\n",
      "5/5 - 7s - loss: 0.1680 - precision: 0.9250 - recall: 0.9250 - f1: 0.9250 - acc: 0.9250 - val_loss: 0.8679 - val_precision: 0.4625 - val_recall: 0.4625 - val_f1: 0.4625 - val_acc: 0.4625 - 7s/epoch - 1s/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.1971 - precision: 0.9500 - recall: 0.9500 - f1: 0.9500 - acc: 0.9500 - val_loss: 0.9335 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1: 0.5000 - val_acc: 0.5000 - 6s/epoch - 1s/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.2103 - precision: 0.9250 - recall: 0.9250 - f1: 0.9250 - acc: 0.9250 - val_loss: 0.9481 - val_precision: 0.4125 - val_recall: 0.4125 - val_f1: 0.4125 - val_acc: 0.4125 - 6s/epoch - 1s/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.52849\n",
      "5/5 - 8s - loss: 0.1809 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 1.0010 - val_precision: 0.4250 - val_recall: 0.4250 - val_f1: 0.4250 - val_acc: 0.4250 - 8s/epoch - 2s/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.52849\n",
      "5/5 - 7s - loss: 0.1983 - precision: 0.9000 - recall: 0.9000 - f1: 0.9000 - acc: 0.9000 - val_loss: 0.8335 - val_precision: 0.5250 - val_recall: 0.5250 - val_f1: 0.5250 - val_acc: 0.5250 - 7s/epoch - 1s/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.52849\n",
      "5/5 - 8s - loss: 0.2084 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 0.8801 - val_precision: 0.4875 - val_recall: 0.4875 - val_f1: 0.4875 - val_acc: 0.4875 - 8s/epoch - 2s/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.1172 - precision: 0.9625 - recall: 0.9625 - f1: 0.9625 - acc: 0.9625 - val_loss: 1.1332 - val_precision: 0.4250 - val_recall: 0.4250 - val_f1: 0.4250 - val_acc: 0.4250 - 6s/epoch - 1s/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.52849\n",
      "5/5 - 8s - loss: 0.2670 - precision: 0.9250 - recall: 0.9250 - f1: 0.9250 - acc: 0.9250 - val_loss: 1.0896 - val_precision: 0.3875 - val_recall: 0.3875 - val_f1: 0.3875 - val_acc: 0.3875 - 8s/epoch - 2s/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.1715 - precision: 0.9250 - recall: 0.9250 - f1: 0.9250 - acc: 0.9250 - val_loss: 0.6870 - val_precision: 0.6000 - val_recall: 0.6000 - val_f1: 0.6000 - val_acc: 0.6000 - 6s/epoch - 1s/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.52849\n",
      "5/5 - 7s - loss: 0.2628 - precision: 0.8750 - recall: 0.8750 - f1: 0.8750 - acc: 0.8750 - val_loss: 0.5610 - val_precision: 0.6875 - val_recall: 0.6875 - val_f1: 0.6875 - val_acc: 0.6875 - 7s/epoch - 1s/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.2055 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 0.6296 - val_precision: 0.6500 - val_recall: 0.6500 - val_f1: 0.6500 - val_acc: 0.6500 - 6s/epoch - 1s/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.1717 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 0.7234 - val_precision: 0.5875 - val_recall: 0.5875 - val_f1: 0.5875 - val_acc: 0.5875 - 6s/epoch - 1s/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.52849\n",
      "5/5 - 8s - loss: 0.3029 - precision: 0.8625 - recall: 0.8625 - f1: 0.8625 - acc: 0.8625 - val_loss: 0.9646 - val_precision: 0.5375 - val_recall: 0.5375 - val_f1: 0.5375 - val_acc: 0.5375 - 8s/epoch - 2s/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.52849\n",
      "5/5 - 9s - loss: 0.1629 - precision: 0.9250 - recall: 0.9250 - f1: 0.9250 - acc: 0.9250 - val_loss: 0.7587 - val_precision: 0.6375 - val_recall: 0.6375 - val_f1: 0.6375 - val_acc: 0.6375 - 9s/epoch - 2s/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.52849\n",
      "5/5 - 7s - loss: 0.2367 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 1.1449 - val_precision: 0.4250 - val_recall: 0.4250 - val_f1: 0.4250 - val_acc: 0.4250 - 7s/epoch - 1s/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.2707 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 1.4671 - val_precision: 0.4500 - val_recall: 0.4500 - val_f1: 0.4500 - val_acc: 0.4500 - 6s/epoch - 1s/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.52849\n",
      "5/5 - 8s - loss: 0.2997 - precision: 0.8750 - recall: 0.8750 - f1: 0.8750 - acc: 0.8750 - val_loss: 2.0428 - val_precision: 0.4250 - val_recall: 0.4250 - val_f1: 0.4250 - val_acc: 0.4250 - 8s/epoch - 2s/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.52849\n",
      "5/5 - 9s - loss: 0.2252 - precision: 0.9000 - recall: 0.9000 - f1: 0.9000 - acc: 0.9000 - val_loss: 2.2583 - val_precision: 0.4375 - val_recall: 0.4375 - val_f1: 0.4375 - val_acc: 0.4375 - 9s/epoch - 2s/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.3823 - precision: 0.8500 - recall: 0.8500 - f1: 0.8500 - acc: 0.8500 - val_loss: 1.8813 - val_precision: 0.4125 - val_recall: 0.4125 - val_f1: 0.4125 - val_acc: 0.4125 - 6s/epoch - 1s/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.52849\n",
      "5/5 - 5s - loss: 0.3445 - precision: 0.8500 - recall: 0.8500 - f1: 0.8500 - acc: 0.8500 - val_loss: 1.0431 - val_precision: 0.6000 - val_recall: 0.6000 - val_f1: 0.6000 - val_acc: 0.6000 - 5s/epoch - 1s/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.52849\n",
      "5/5 - 6s - loss: 0.2436 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 0.6696 - val_precision: 0.7500 - val_recall: 0.7500 - val_f1: 0.7500 - val_acc: 0.7500 - 6s/epoch - 1s/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.52849 to 0.44265, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 6s - loss: 0.1627 - precision: 0.9625 - recall: 0.9625 - f1: 0.9625 - acc: 0.9625 - val_loss: 0.4427 - val_precision: 0.8375 - val_recall: 0.8375 - val_f1: 0.8375 - val_acc: 0.8375 - 6s/epoch - 1s/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.44265\n",
      "5/5 - 6s - loss: 0.2406 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 0.4598 - val_precision: 0.7625 - val_recall: 0.7625 - val_f1: 0.7625 - val_acc: 0.7625 - 6s/epoch - 1s/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.44265\n",
      "5/5 - 8s - loss: 0.3572 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 0.9680 - val_precision: 0.5625 - val_recall: 0.5625 - val_f1: 0.5625 - val_acc: 0.5625 - 8s/epoch - 2s/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.44265\n",
      "5/5 - 7s - loss: 0.2242 - precision: 0.9250 - recall: 0.9250 - f1: 0.9250 - acc: 0.9250 - val_loss: 1.5950 - val_precision: 0.5875 - val_recall: 0.5875 - val_f1: 0.5875 - val_acc: 0.5875 - 7s/epoch - 1s/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.44265\n",
      "5/5 - 7s - loss: 0.2635 - precision: 0.9250 - recall: 0.9250 - f1: 0.9250 - acc: 0.9250 - val_loss: 1.4797 - val_precision: 0.5625 - val_recall: 0.5625 - val_f1: 0.5625 - val_acc: 0.5625 - 7s/epoch - 1s/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.44265\n",
      "5/5 - 6s - loss: 0.2878 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 0.7748 - val_precision: 0.7250 - val_recall: 0.7250 - val_f1: 0.7250 - val_acc: 0.7250 - 6s/epoch - 1s/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.44265\n",
      "5/5 - 6s - loss: 0.3055 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 0.5639 - val_precision: 0.7750 - val_recall: 0.7750 - val_f1: 0.7750 - val_acc: 0.7750 - 6s/epoch - 1s/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.44265\n",
      "5/5 - 6s - loss: 0.3143 - precision: 0.9000 - recall: 0.9000 - f1: 0.9000 - acc: 0.9000 - val_loss: 0.7506 - val_precision: 0.7375 - val_recall: 0.7375 - val_f1: 0.7375 - val_acc: 0.7375 - 6s/epoch - 1s/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.44265 to 0.40849, saving model to BRAIN_TUMOR_FOLD_0.h5\n",
      "5/5 - 6s - loss: 0.2433 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 0.4085 - val_precision: 0.8500 - val_recall: 0.8500 - val_f1: 0.8500 - val_acc: 0.8500 - 6s/epoch - 1s/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.40849\n",
      "5/5 - 6s - loss: 0.1547 - precision: 0.9250 - recall: 0.9250 - f1: 0.9250 - acc: 0.9250 - val_loss: 0.4978 - val_precision: 0.8000 - val_recall: 0.8000 - val_f1: 0.8000 - val_acc: 0.8000 - 6s/epoch - 1s/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.40849\n",
      "5/5 - 7s - loss: 0.1910 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 0.9663 - val_precision: 0.6375 - val_recall: 0.6375 - val_f1: 0.6375 - val_acc: 0.6375 - 7s/epoch - 1s/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.40849\n",
      "5/5 - 6s - loss: 0.2189 - precision: 0.9500 - recall: 0.9500 - f1: 0.9500 - acc: 0.9500 - val_loss: 1.0120 - val_precision: 0.6250 - val_recall: 0.6250 - val_f1: 0.6250 - val_acc: 0.6250 - 6s/epoch - 1s/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.40849\n",
      "5/5 - 8s - loss: 0.1626 - precision: 0.9625 - recall: 0.9625 - f1: 0.9625 - acc: 0.9625 - val_loss: 1.4595 - val_precision: 0.5750 - val_recall: 0.5750 - val_f1: 0.5750 - val_acc: 0.5750 - 8s/epoch - 2s/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.40849\n",
      "5/5 - 9s - loss: 0.2274 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 1.6622 - val_precision: 0.5750 - val_recall: 0.5750 - val_f1: 0.5750 - val_acc: 0.5750 - 9s/epoch - 2s/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.40849\n",
      "5/5 - 6s - loss: 0.1140 - precision: 0.9750 - recall: 0.9750 - f1: 0.9750 - acc: 0.9750 - val_loss: 1.5997 - val_precision: 0.5375 - val_recall: 0.5375 - val_f1: 0.5375 - val_acc: 0.5375 - 6s/epoch - 1s/step\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40278, saving model to BRAIN_TUMOR_FOLD_1.h5\n",
      "5/5 - 12s - loss: 0.4562 - precision: 0.8375 - recall: 0.8375 - f1: 0.8375 - acc: 0.8375 - val_loss: 0.4028 - val_precision: 0.7625 - val_recall: 0.7625 - val_f1: 0.7625 - val_acc: 0.7625 - 12s/epoch - 2s/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40278 to 0.38734, saving model to BRAIN_TUMOR_FOLD_1.h5\n",
      "5/5 - 6s - loss: 0.8706 - precision: 0.6625 - recall: 0.6625 - f1: 0.6625 - acc: 0.6625 - val_loss: 0.3873 - val_precision: 0.7875 - val_recall: 0.7875 - val_f1: 0.7875 - val_acc: 0.7875 - 6s/epoch - 1s/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.4886 - precision: 0.7875 - recall: 0.7875 - f1: 0.7875 - acc: 0.7875 - val_loss: 0.6415 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 6s/epoch - 1s/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.5029 - precision: 0.7750 - recall: 0.7750 - f1: 0.7750 - acc: 0.7750 - val_loss: 0.5236 - val_precision: 0.6500 - val_recall: 0.6500 - val_f1: 0.6500 - val_acc: 0.6500 - 8s/epoch - 2s/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.5477 - precision: 0.7750 - recall: 0.7750 - f1: 0.7750 - acc: 0.7750 - val_loss: 0.6965 - val_precision: 0.6625 - val_recall: 0.6625 - val_f1: 0.6625 - val_acc: 0.6625 - 6s/epoch - 1s/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.3582 - precision: 0.8500 - recall: 0.8500 - f1: 0.8500 - acc: 0.8500 - val_loss: 0.7122 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 6s/epoch - 1s/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.3926 - precision: 0.8000 - recall: 0.8000 - f1: 0.8000 - acc: 0.8000 - val_loss: 0.8018 - val_precision: 0.6250 - val_recall: 0.6250 - val_f1: 0.6250 - val_acc: 0.6250 - 6s/epoch - 1s/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.3154 - precision: 0.9000 - recall: 0.9000 - f1: 0.9000 - acc: 0.9000 - val_loss: 0.8883 - val_precision: 0.6250 - val_recall: 0.6250 - val_f1: 0.6250 - val_acc: 0.6250 - 8s/epoch - 2s/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2704 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 0.8268 - val_precision: 0.6125 - val_recall: 0.6125 - val_f1: 0.6125 - val_acc: 0.6125 - 8s/epoch - 2s/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.3935 - precision: 0.8375 - recall: 0.8375 - f1: 0.8375 - acc: 0.8375 - val_loss: 0.9414 - val_precision: 0.5875 - val_recall: 0.5875 - val_f1: 0.5875 - val_acc: 0.5875 - 7s/epoch - 1s/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2061 - precision: 0.9625 - recall: 0.9625 - f1: 0.9625 - acc: 0.9625 - val_loss: 0.7004 - val_precision: 0.7625 - val_recall: 0.7625 - val_f1: 0.7625 - val_acc: 0.7625 - 8s/epoch - 2s/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.2897 - precision: 0.8750 - recall: 0.8750 - f1: 0.8750 - acc: 0.8750 - val_loss: 1.1410 - val_precision: 0.7125 - val_recall: 0.7125 - val_f1: 0.7125 - val_acc: 0.7125 - 7s/epoch - 1s/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.6022 - precision: 0.8125 - recall: 0.8125 - f1: 0.8125 - acc: 0.8125 - val_loss: 1.0344 - val_precision: 0.6000 - val_recall: 0.6000 - val_f1: 0.6000 - val_acc: 0.6000 - 8s/epoch - 2s/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2462 - precision: 0.8750 - recall: 0.8750 - f1: 0.8750 - acc: 0.8750 - val_loss: 0.6142 - val_precision: 0.7750 - val_recall: 0.7750 - val_f1: 0.7750 - val_acc: 0.7750 - 8s/epoch - 2s/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2675 - precision: 0.8750 - recall: 0.8750 - f1: 0.8750 - acc: 0.8750 - val_loss: 0.7865 - val_precision: 0.6375 - val_recall: 0.6375 - val_f1: 0.6375 - val_acc: 0.6375 - 8s/epoch - 2s/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.3484 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 0.6476 - val_precision: 0.7000 - val_recall: 0.7000 - val_f1: 0.7000 - val_acc: 0.7000 - 8s/epoch - 2s/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.4181 - precision: 0.8250 - recall: 0.8250 - f1: 0.8250 - acc: 0.8250 - val_loss: 0.8802 - val_precision: 0.7000 - val_recall: 0.7000 - val_f1: 0.7000 - val_acc: 0.7000 - 8s/epoch - 2s/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2803 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 0.5033 - val_precision: 0.7750 - val_recall: 0.7750 - val_f1: 0.7750 - val_acc: 0.7750 - 8s/epoch - 2s/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.3048 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 0.7591 - val_precision: 0.7000 - val_recall: 0.7000 - val_f1: 0.7000 - val_acc: 0.7000 - 7s/epoch - 1s/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2977 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 1.1824 - val_precision: 0.5750 - val_recall: 0.5750 - val_f1: 0.5750 - val_acc: 0.5750 - 8s/epoch - 2s/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2195 - precision: 0.9000 - recall: 0.9000 - f1: 0.9000 - acc: 0.9000 - val_loss: 1.1802 - val_precision: 0.4750 - val_recall: 0.4750 - val_f1: 0.4750 - val_acc: 0.4750 - 8s/epoch - 2s/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.3399 - precision: 0.8500 - recall: 0.8500 - f1: 0.8500 - acc: 0.8500 - val_loss: 0.7436 - val_precision: 0.6500 - val_recall: 0.6500 - val_f1: 0.6500 - val_acc: 0.6500 - 7s/epoch - 1s/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.3060 - precision: 0.8625 - recall: 0.8625 - f1: 0.8625 - acc: 0.8625 - val_loss: 0.5797 - val_precision: 0.7750 - val_recall: 0.7750 - val_f1: 0.7750 - val_acc: 0.7750 - 8s/epoch - 2s/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.3053 - precision: 0.8625 - recall: 0.8625 - f1: 0.8625 - acc: 0.8625 - val_loss: 0.6997 - val_precision: 0.7125 - val_recall: 0.7125 - val_f1: 0.7125 - val_acc: 0.7125 - 6s/epoch - 1s/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.1532 - precision: 0.9500 - recall: 0.9500 - f1: 0.9500 - acc: 0.9500 - val_loss: 0.7976 - val_precision: 0.7500 - val_recall: 0.7500 - val_f1: 0.7500 - val_acc: 0.7500 - 6s/epoch - 1s/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2064 - precision: 0.9000 - recall: 0.9000 - f1: 0.9000 - acc: 0.9000 - val_loss: 0.7245 - val_precision: 0.7125 - val_recall: 0.7125 - val_f1: 0.7125 - val_acc: 0.7125 - 8s/epoch - 2s/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.3226 - precision: 0.8500 - recall: 0.8500 - f1: 0.8500 - acc: 0.8500 - val_loss: 0.6384 - val_precision: 0.7875 - val_recall: 0.7875 - val_f1: 0.7875 - val_acc: 0.7875 - 6s/epoch - 1s/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.1887 - precision: 0.9250 - recall: 0.9250 - f1: 0.9250 - acc: 0.9250 - val_loss: 0.5607 - val_precision: 0.8000 - val_recall: 0.8000 - val_f1: 0.8000 - val_acc: 0.8000 - 8s/epoch - 2s/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.3116 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 0.6251 - val_precision: 0.7875 - val_recall: 0.7875 - val_f1: 0.7875 - val_acc: 0.7875 - 8s/epoch - 2s/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.1579 - precision: 0.9500 - recall: 0.9500 - f1: 0.9500 - acc: 0.9500 - val_loss: 0.5490 - val_precision: 0.8500 - val_recall: 0.8500 - val_f1: 0.8500 - val_acc: 0.8500 - 6s/epoch - 1s/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.4399 - precision: 0.8375 - recall: 0.8375 - f1: 0.8375 - acc: 0.8375 - val_loss: 0.6923 - val_precision: 0.7375 - val_recall: 0.7375 - val_f1: 0.7375 - val_acc: 0.7375 - 7s/epoch - 1s/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.38734\n",
      "5/5 - 5s - loss: 0.4790 - precision: 0.8625 - recall: 0.8625 - f1: 0.8625 - acc: 0.8625 - val_loss: 0.6271 - val_precision: 0.7500 - val_recall: 0.7500 - val_f1: 0.7500 - val_acc: 0.7500 - 5s/epoch - 1s/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.2594 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 1.2550 - val_precision: 0.6000 - val_recall: 0.6000 - val_f1: 0.6000 - val_acc: 0.6000 - 7s/epoch - 1s/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.2850 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 0.8402 - val_precision: 0.6375 - val_recall: 0.6375 - val_f1: 0.6375 - val_acc: 0.6375 - 7s/epoch - 1s/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.3834 - precision: 0.8000 - recall: 0.8000 - f1: 0.8000 - acc: 0.8000 - val_loss: 0.7876 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 8s/epoch - 2s/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.3041 - precision: 0.8750 - recall: 0.8750 - f1: 0.8750 - acc: 0.8750 - val_loss: 0.4855 - val_precision: 0.8000 - val_recall: 0.8000 - val_f1: 0.8000 - val_acc: 0.8000 - 7s/epoch - 1s/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.4180 - precision: 0.8125 - recall: 0.8125 - f1: 0.8125 - acc: 0.8125 - val_loss: 0.7013 - val_precision: 0.7000 - val_recall: 0.7000 - val_f1: 0.7000 - val_acc: 0.7000 - 8s/epoch - 2s/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.1654 - precision: 0.9500 - recall: 0.9500 - f1: 0.9500 - acc: 0.9500 - val_loss: 0.4604 - val_precision: 0.8375 - val_recall: 0.8375 - val_f1: 0.8375 - val_acc: 0.8375 - 6s/epoch - 1s/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2278 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 0.8747 - val_precision: 0.6625 - val_recall: 0.6625 - val_f1: 0.6625 - val_acc: 0.6625 - 8s/epoch - 2s/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2908 - precision: 0.8625 - recall: 0.8625 - f1: 0.8625 - acc: 0.8625 - val_loss: 0.7143 - val_precision: 0.7000 - val_recall: 0.7000 - val_f1: 0.7000 - val_acc: 0.7000 - 8s/epoch - 2s/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.2756 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 0.4792 - val_precision: 0.7625 - val_recall: 0.7625 - val_f1: 0.7625 - val_acc: 0.7625 - 6s/epoch - 1s/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2431 - precision: 0.9000 - recall: 0.9000 - f1: 0.9000 - acc: 0.9000 - val_loss: 0.4606 - val_precision: 0.8500 - val_recall: 0.8500 - val_f1: 0.8500 - val_acc: 0.8500 - 8s/epoch - 2s/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.2102 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 3.0811 - val_precision: 0.4000 - val_recall: 0.4000 - val_f1: 0.4000 - val_acc: 0.4000 - 6s/epoch - 1s/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2055 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 3.2077 - val_precision: 0.4375 - val_recall: 0.4375 - val_f1: 0.4375 - val_acc: 0.4375 - 8s/epoch - 2s/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2081 - precision: 0.9500 - recall: 0.9500 - f1: 0.9500 - acc: 0.9500 - val_loss: 2.1379 - val_precision: 0.3750 - val_recall: 0.3750 - val_f1: 0.3750 - val_acc: 0.3750 - 8s/epoch - 2s/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.1634 - precision: 0.9500 - recall: 0.9500 - f1: 0.9500 - acc: 0.9500 - val_loss: 0.8196 - val_precision: 0.7125 - val_recall: 0.7125 - val_f1: 0.7125 - val_acc: 0.7125 - 7s/epoch - 1s/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2759 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 1.7592 - val_precision: 0.4875 - val_recall: 0.4875 - val_f1: 0.4875 - val_acc: 0.4875 - 8s/epoch - 2s/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.1561 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 2.0272 - val_precision: 0.4625 - val_recall: 0.4625 - val_f1: 0.4625 - val_acc: 0.4625 - 8s/epoch - 2s/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.1490 - precision: 0.9625 - recall: 0.9625 - f1: 0.9625 - acc: 0.9625 - val_loss: 2.1231 - val_precision: 0.4500 - val_recall: 0.4500 - val_f1: 0.4500 - val_acc: 0.4500 - 8s/epoch - 2s/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.1308 - precision: 0.9500 - recall: 0.9500 - f1: 0.9500 - acc: 0.9500 - val_loss: 1.5836 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1: 0.5000 - val_acc: 0.5000 - 7s/epoch - 1s/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.1567 - precision: 0.9750 - recall: 0.9750 - f1: 0.9750 - acc: 0.9750 - val_loss: 1.6646 - val_precision: 0.5625 - val_recall: 0.5625 - val_f1: 0.5625 - val_acc: 0.5625 - 8s/epoch - 2s/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.1667 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 1.2221 - val_precision: 0.6500 - val_recall: 0.6500 - val_f1: 0.6500 - val_acc: 0.6500 - 7s/epoch - 1s/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.1438 - precision: 0.9500 - recall: 0.9500 - f1: 0.9500 - acc: 0.9500 - val_loss: 2.1731 - val_precision: 0.4625 - val_recall: 0.4625 - val_f1: 0.4625 - val_acc: 0.4625 - 8s/epoch - 2s/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2754 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 2.7638 - val_precision: 0.4625 - val_recall: 0.4625 - val_f1: 0.4625 - val_acc: 0.4625 - 8s/epoch - 2s/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.1483 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 3.8725 - val_precision: 0.3125 - val_recall: 0.3125 - val_f1: 0.3125 - val_acc: 0.3125 - 6s/epoch - 1s/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.1603 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 3.2187 - val_precision: 0.4250 - val_recall: 0.4250 - val_f1: 0.4250 - val_acc: 0.4250 - 8s/epoch - 2s/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.1502 - precision: 0.9500 - recall: 0.9500 - f1: 0.9500 - acc: 0.9500 - val_loss: 3.0460 - val_precision: 0.5125 - val_recall: 0.5125 - val_f1: 0.5125 - val_acc: 0.5125 - 6s/epoch - 1s/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.3622 - precision: 0.8625 - recall: 0.8625 - f1: 0.8625 - acc: 0.8625 - val_loss: 2.4694 - val_precision: 0.4625 - val_recall: 0.4625 - val_f1: 0.4625 - val_acc: 0.4625 - 6s/epoch - 1s/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.1983 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 2.3447 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1: 0.5000 - val_acc: 0.5000 - 7s/epoch - 1s/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.0979 - precision: 0.9625 - recall: 0.9625 - f1: 0.9625 - acc: 0.9625 - val_loss: 2.5419 - val_precision: 0.5125 - val_recall: 0.5125 - val_f1: 0.5125 - val_acc: 0.5125 - 8s/epoch - 2s/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.1784 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 1.6836 - val_precision: 0.6250 - val_recall: 0.6250 - val_f1: 0.6250 - val_acc: 0.6250 - 6s/epoch - 1s/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.1634 - precision: 0.9500 - recall: 0.9500 - f1: 0.9500 - acc: 0.9500 - val_loss: 1.6244 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 6s/epoch - 1s/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.0639 - precision: 0.9875 - recall: 0.9875 - f1: 0.9875 - acc: 0.9875 - val_loss: 1.2233 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 8s/epoch - 2s/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.1229 - precision: 0.9625 - recall: 0.9625 - f1: 0.9625 - acc: 0.9625 - val_loss: 0.8514 - val_precision: 0.7125 - val_recall: 0.7125 - val_f1: 0.7125 - val_acc: 0.7125 - 8s/epoch - 2s/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.1528 - precision: 0.9625 - recall: 0.9625 - f1: 0.9625 - acc: 0.9625 - val_loss: 1.1448 - val_precision: 0.6125 - val_recall: 0.6125 - val_f1: 0.6125 - val_acc: 0.6125 - 8s/epoch - 2s/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.1737 - precision: 0.9250 - recall: 0.9250 - f1: 0.9250 - acc: 0.9250 - val_loss: 0.8054 - val_precision: 0.7125 - val_recall: 0.7125 - val_f1: 0.7125 - val_acc: 0.7125 - 6s/epoch - 1s/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.0828 - precision: 0.9750 - recall: 0.9750 - f1: 0.9750 - acc: 0.9750 - val_loss: 0.6883 - val_precision: 0.7875 - val_recall: 0.7875 - val_f1: 0.7875 - val_acc: 0.7875 - 8s/epoch - 2s/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.0852 - precision: 0.9625 - recall: 0.9625 - f1: 0.9625 - acc: 0.9625 - val_loss: 0.7809 - val_precision: 0.7375 - val_recall: 0.7375 - val_f1: 0.7375 - val_acc: 0.7375 - 8s/epoch - 2s/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.0889 - precision: 0.9625 - recall: 0.9625 - f1: 0.9625 - acc: 0.9625 - val_loss: 1.0731 - val_precision: 0.6500 - val_recall: 0.6500 - val_f1: 0.6500 - val_acc: 0.6500 - 6s/epoch - 1s/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.1249 - precision: 0.9500 - recall: 0.9500 - f1: 0.9500 - acc: 0.9500 - val_loss: 1.1169 - val_precision: 0.6000 - val_recall: 0.6000 - val_f1: 0.6000 - val_acc: 0.6000 - 8s/epoch - 2s/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.1431 - precision: 0.9625 - recall: 0.9625 - f1: 0.9625 - acc: 0.9625 - val_loss: 1.6266 - val_precision: 0.5750 - val_recall: 0.5750 - val_f1: 0.5750 - val_acc: 0.5750 - 8s/epoch - 2s/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2116 - precision: 0.9250 - recall: 0.9250 - f1: 0.9250 - acc: 0.9250 - val_loss: 0.5610 - val_precision: 0.7500 - val_recall: 0.7500 - val_f1: 0.7500 - val_acc: 0.7500 - 8s/epoch - 2s/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.3560 - precision: 0.8500 - recall: 0.8500 - f1: 0.8500 - acc: 0.8500 - val_loss: 0.5250 - val_precision: 0.7875 - val_recall: 0.7875 - val_f1: 0.7875 - val_acc: 0.7875 - 6s/epoch - 1s/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.38734\n",
      "5/5 - 5s - loss: 0.1507 - precision: 0.9625 - recall: 0.9625 - f1: 0.9625 - acc: 0.9625 - val_loss: 1.7634 - val_precision: 0.5625 - val_recall: 0.5625 - val_f1: 0.5625 - val_acc: 0.5625 - 5s/epoch - 1s/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2090 - precision: 0.9250 - recall: 0.9250 - f1: 0.9250 - acc: 0.9250 - val_loss: 0.5032 - val_precision: 0.8125 - val_recall: 0.8125 - val_f1: 0.8125 - val_acc: 0.8125 - 8s/epoch - 2s/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.3148 - precision: 0.8625 - recall: 0.8625 - f1: 0.8625 - acc: 0.8625 - val_loss: 0.4587 - val_precision: 0.7875 - val_recall: 0.7875 - val_f1: 0.7875 - val_acc: 0.7875 - 8s/epoch - 2s/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.3595 - precision: 0.8500 - recall: 0.8500 - f1: 0.8500 - acc: 0.8500 - val_loss: 0.5806 - val_precision: 0.7250 - val_recall: 0.7250 - val_f1: 0.7250 - val_acc: 0.7250 - 7s/epoch - 1s/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2573 - precision: 0.9000 - recall: 0.9000 - f1: 0.9000 - acc: 0.9000 - val_loss: 0.7247 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 8s/epoch - 2s/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.3524 - precision: 0.8500 - recall: 0.8500 - f1: 0.8500 - acc: 0.8500 - val_loss: 0.4345 - val_precision: 0.8375 - val_recall: 0.8375 - val_f1: 0.8375 - val_acc: 0.8375 - 6s/epoch - 1s/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.38734\n",
      "5/5 - 5s - loss: 0.3547 - precision: 0.8750 - recall: 0.8750 - f1: 0.8750 - acc: 0.8750 - val_loss: 0.6985 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 5s/epoch - 1s/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.2596 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 1.9091 - val_precision: 0.4375 - val_recall: 0.4375 - val_f1: 0.4375 - val_acc: 0.4375 - 6s/epoch - 1s/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.4605 - precision: 0.8125 - recall: 0.8125 - f1: 0.8125 - acc: 0.8125 - val_loss: 1.3784 - val_precision: 0.5125 - val_recall: 0.5125 - val_f1: 0.5125 - val_acc: 0.5125 - 8s/epoch - 2s/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.3209 - precision: 0.8750 - recall: 0.8750 - f1: 0.8750 - acc: 0.8750 - val_loss: 1.5025 - val_precision: 0.4375 - val_recall: 0.4375 - val_f1: 0.4375 - val_acc: 0.4375 - 6s/epoch - 1s/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.1821 - precision: 0.9250 - recall: 0.9250 - f1: 0.9250 - acc: 0.9250 - val_loss: 1.1048 - val_precision: 0.7125 - val_recall: 0.7125 - val_f1: 0.7125 - val_acc: 0.7125 - 6s/epoch - 1s/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.2888 - precision: 0.8750 - recall: 0.8750 - f1: 0.8750 - acc: 0.8750 - val_loss: 1.1020 - val_precision: 0.6875 - val_recall: 0.6875 - val_f1: 0.6875 - val_acc: 0.6875 - 6s/epoch - 1s/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.2881 - precision: 0.8625 - recall: 0.8625 - f1: 0.8625 - acc: 0.8625 - val_loss: 1.1659 - val_precision: 0.7375 - val_recall: 0.7375 - val_f1: 0.7375 - val_acc: 0.7375 - 6s/epoch - 1s/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.1619 - precision: 0.9500 - recall: 0.9500 - f1: 0.9500 - acc: 0.9500 - val_loss: 2.0299 - val_precision: 0.6375 - val_recall: 0.6375 - val_f1: 0.6375 - val_acc: 0.6375 - 8s/epoch - 2s/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.1884 - precision: 0.9250 - recall: 0.9250 - f1: 0.9250 - acc: 0.9250 - val_loss: 1.7261 - val_precision: 0.6750 - val_recall: 0.6750 - val_f1: 0.6750 - val_acc: 0.6750 - 8s/epoch - 2s/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.3202 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 0.4205 - val_precision: 0.7750 - val_recall: 0.7750 - val_f1: 0.7750 - val_acc: 0.7750 - 8s/epoch - 2s/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.2332 - precision: 0.8750 - recall: 0.8750 - f1: 0.8750 - acc: 0.8750 - val_loss: 0.6476 - val_precision: 0.7375 - val_recall: 0.7375 - val_f1: 0.7375 - val_acc: 0.7375 - 6s/epoch - 1s/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2172 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 1.6720 - val_precision: 0.5125 - val_recall: 0.5125 - val_f1: 0.5125 - val_acc: 0.5125 - 8s/epoch - 2s/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.2581 - precision: 0.8875 - recall: 0.8875 - f1: 0.8875 - acc: 0.8875 - val_loss: 1.2743 - val_precision: 0.5500 - val_recall: 0.5500 - val_f1: 0.5500 - val_acc: 0.5500 - 8s/epoch - 2s/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.1639 - precision: 0.9375 - recall: 0.9375 - f1: 0.9375 - acc: 0.9375 - val_loss: 1.1892 - val_precision: 0.5875 - val_recall: 0.5875 - val_f1: 0.5875 - val_acc: 0.5875 - 7s/epoch - 1s/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.4336 - precision: 0.8000 - recall: 0.8000 - f1: 0.8000 - acc: 0.8000 - val_loss: 0.7022 - val_precision: 0.7000 - val_recall: 0.7000 - val_f1: 0.7000 - val_acc: 0.7000 - 7s/epoch - 1s/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.0752 - precision: 1.0000 - recall: 1.0000 - f1: 1.0000 - acc: 1.0000 - val_loss: 1.4096 - val_precision: 0.5250 - val_recall: 0.5250 - val_f1: 0.5250 - val_acc: 0.5250 - 8s/epoch - 2s/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.38734\n",
      "5/5 - 8s - loss: 0.1632 - precision: 0.9625 - recall: 0.9625 - f1: 0.9625 - acc: 0.9625 - val_loss: 0.4340 - val_precision: 0.8375 - val_recall: 0.8375 - val_f1: 0.8375 - val_acc: 0.8375 - 8s/epoch - 2s/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.38734\n",
      "5/5 - 6s - loss: 0.2527 - precision: 0.9000 - recall: 0.9000 - f1: 0.9000 - acc: 0.9000 - val_loss: 0.4089 - val_precision: 0.8375 - val_recall: 0.8375 - val_f1: 0.8375 - val_acc: 0.8375 - 6s/epoch - 1s/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.38734\n",
      "5/5 - 7s - loss: 0.1453 - precision: 0.9625 - recall: 0.9625 - f1: 0.9625 - acc: 0.9625 - val_loss: 0.5271 - val_precision: 0.8000 - val_recall: 0.8000 - val_f1: 0.8000 - val_acc: 0.8000 - 7s/epoch - 1s/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.38734 to 0.33527, saving model to BRAIN_TUMOR_FOLD_1.h5\n",
      "5/5 - 7s - loss: 0.2815 - precision: 0.9125 - recall: 0.9125 - f1: 0.9125 - acc: 0.9125 - val_loss: 0.3353 - val_precision: 0.8625 - val_recall: 0.8625 - val_f1: 0.8625 - val_acc: 0.8625 - 7s/epoch - 1s/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33527\n",
      "5/5 - 7s - loss: 0.2849 - precision: 0.9000 - recall: 0.9000 - f1: 0.9000 - acc: 0.9000 - val_loss: 0.3681 - val_precision: 0.8375 - val_recall: 0.8375 - val_f1: 0.8375 - val_acc: 0.8375 - 7s/epoch - 1s/step\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=N_SPLITS, random_state=SEED, shuffle=True)\n",
    "\n",
    "for ix, (train_index, test_index) in enumerate(kf.split(range(len(dataset.split_train_test(\"train\")[0])))):\n",
    "                                               \n",
    "    tg = DATASET(SHAPE, BATCH_SIZE, train_index, BASE_DIR, SEED, TRAIN_TEST_RATIO, augment=True)\n",
    "    vg = DATASET(SHAPE, BATCH_SIZE, test_index , BASE_DIR, SEED, TRAIN_TEST_RATIO, augment=False)\n",
    "        \n",
    "    schedule = SGDRScheduler(min_lr=1e-6,            # 1e-6 oldu\n",
    "                             max_lr=1e-3,      # 1e-2 oldu\n",
    "                             steps_per_epoch=5,\n",
    "                             lr_decay=0.9,  #0.9 oldu\n",
    "                             cycle_length=10,  #10 oldu\n",
    "                             mult_factor=2)   #2. oldu\n",
    "                                                              #adam(lr=1e-2) oldu\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=1e-4,beta_1=0.9,beta_2=0.999,), metrics=[precision, recall, f1, 'acc'])\n",
    "\n",
    "    model_ckpt = \"BRAIN_TUMOR_FOLD_\"+str(ix)+\".h5\"\n",
    "    callbacks = [ModelCheckpoint(model_ckpt, monitor='val_loss', mode='min', verbose=1, save_best_only=True, save_weights_only=False),\n",
    "                 TensorBoard(log_dir='./log_'+str(ix), update_freq='batch'), \n",
    "                 schedule] \n",
    "                                               \n",
    "    model.fit(tg.data_generator(),\n",
    "                        steps_per_epoch=5,\n",
    "                        epochs=EPOCHS,\n",
    "                        verbose=2,\n",
    "                        validation_data=vg.data_generator(),\n",
    "                        validation_steps=5,\n",
    "                        callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3I83S5TU4jZX"
   },
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    gen = DATASET(SHAPE, BATCH_SIZE, range(1), BASE_DIR, SEED, TRAIN_TEST_RATIO, augment=False).split_train_test(\"test\")\n",
    "                       \n",
    "    x = np.empty((len(gen[0]),)+SHAPE, dtype=np.float32)\n",
    "    y = np.empty((len(gen[1]), 2), dtype=np.float32)\n",
    "    \n",
    "    for ix, path in tqdm(enumerate(gen[0])):\n",
    "        img = np.array(Image.open(gen[0][ix]))\n",
    "        img = resize(img, SHAPE)\n",
    "\n",
    "        label = gen[1][ix]\n",
    "\n",
    "        x[ix] = img\n",
    "        y[ix] = label\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2833,
     "status": "ok",
     "timestamp": 1636619403798,
     "user": {
      "displayName": "Shyam 5 project",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01454073121946861679"
     },
     "user_tz": -330
    },
    "id": "EDnun27N4jZa",
    "outputId": "57ed872b-eb92-4f7d-c44d-b0755c01d061"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:02, 34.52it/s]\n"
     ]
    }
   ],
   "source": [
    "x, y = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCjjF4vm4jZd"
   },
   "outputs": [],
   "source": [
    "# Threshold predictions with THRESH_VAL\n",
    "def threshold_arr(array):\n",
    "    # Get all value from array\n",
    "    # Compare calue with THRESH_VAL \n",
    "    # IF value >= THRESH_VAL. round to 1\n",
    "    # ELSE. round to 0\n",
    "    new_arr = []\n",
    "    for ix, val in enumerate(array):\n",
    "        loc = np.array(val).argmax(axis=0)\n",
    "        k = list(np.zeros((len(val)), dtype=np.float32))\n",
    "        k[loc]=1\n",
    "        new_arr.append(k)\n",
    "        \n",
    "    return np.array(new_arr, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4965,
     "status": "ok",
     "timestamp": 1636619416791,
     "user": {
      "displayName": "Shyam 5 project",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01454073121946861679"
     },
     "user_tz": -330
    },
    "id": "MIOdFm1Y4jZg",
    "outputId": "4803f62b-ed39-4cf2-db5e-c11bc9b76840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6528113484382629, 0.78125, 0.78125, 0.7812499403953552, 0.7749999761581421]\n",
      "[0.6088347434997559, 0.78125, 0.78125, 0.7812499403953552, 0.7875000238418579]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = []\n",
    "for i in range(2):\n",
    "    model = load_model(\"BRAIN_TUMOR_FOLD_{}.h5\".format(i), custom_objects={'f1': f1, 'precision': precision, 'recall': recall})\n",
    "    print(model.evaluate(x, y, verbose=0))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVq6AwMb4jZn"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.savefig(\"confusion matrix_best.jpg\", dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "executionInfo": {
     "elapsed": 2527,
     "status": "ok",
     "timestamp": 1636619429252,
     "user": {
      "displayName": "Shyam 5 project",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01454073121946861679"
     },
     "user_tz": -330
    },
    "id": "57JHUoqj4jZr",
    "outputId": "dd1f691e-1c09-4571-95fb-51cdf02f7016"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.775, F1_Score: 0.765625, Precision: 0.7633784655061251, Recall: 0.7689269256089533\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81        49\n",
      "           1       0.70      0.74      0.72        31\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        80\n",
      "   macro avg       0.76      0.77      0.77        80\n",
      "weighted avg       0.78      0.78      0.78        80\n",
      " samples avg       0.78      0.78      0.78        80\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_preds = threshold_arr(models[0].predict(x, verbose=0))\n",
    "\n",
    "results = precision_recall_fscore_support(y, y_preds ,average='macro')\n",
    "acc = accuracy_score(y, y_preds)\n",
    "\n",
    "print(\"Accuracy: {}, F1_Score: {}, Precision: {}, Recall: {}\".format(acc, results[2], results[0], results[1]))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y, y_preds))\n",
    "print(\"\\n\")\n",
    "cnf_matrix = confusion_matrix(y.argmax(axis=1), y_preds.argmax(axis=1))\n",
    "\n",
    "plot_confusion_matrix(cm           = cnf_matrix, \n",
    "                      normalize    = False,\n",
    "                      target_names = ['Meningioma', 'Glioma','Pituitary'],\n",
    "                      title        = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 1211,
     "status": "ok",
     "timestamp": 1636619435335,
     "user": {
      "displayName": "Shyam 5 project",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01454073121946861679"
     },
     "user_tz": -330
    },
    "id": "d2v7WuVR4jZw",
    "outputId": "90ae30a3-a0c8-4bf4-e031-052d22edf4ce"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "y_pred = models[0].predict(x, verbose=0)\n",
    "y_proba = []\n",
    "for ix, i in enumerate(y_pred.argmax(axis=1)):\n",
    "    if i==0:\n",
    "        y_proba.append(1-y_pred[ix][i])\n",
    "    else:\n",
    "        y_proba.append(y_pred[ix][i])\n",
    "        \n",
    "fpr, tpr, thresholds = roc_curve(y.argmax(axis=1), y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, label='Brain Tumor Classification (AUC = {})'.format(round(roc_auc,3)))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"ROC_best.jpg\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-XjLqiH9fBO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BrainMRNet_main_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
